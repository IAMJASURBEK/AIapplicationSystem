{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAMJASURBEK/AIapplicationSystem/blob/main/week10/week10_session2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week 10 Lab 1-1"
      ],
      "metadata": {
        "id": "OytPaOraAlDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with a number of import statements"
      ],
      "metadata": {
        "id": "Cbct_jOqAiwC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fE5wsjIp9lqW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we then load one of the images with the function\n",
        "open , which will return an image in PIL format. We specified that we\n",
        "want the picture to be scaled to 224Ã—224 pixels because that is what the\n",
        "ResNet-50 implementation expects. We then convert the image into a\n",
        "NumPy tensor to be able to present it to our network. The network expects\n",
        "an array of multiple images, so we add a fourth dimension; consequently,\n",
        "we have an array of images with a single element"
      ],
      "metadata": {
        "id": "8LTnFsrCAsCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess image.\n",
        "\n",
        "image = Image.open('/content/dog.jpeg')\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "\n",
        "  transforms.Resize((224, 224)),\n",
        "\n",
        "  transforms.ToTensor(),\n",
        "\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) # Parameters are documented at pytorch.org.\n",
        "\n",
        "input_tensor = preprocess(image)\n",
        "\n",
        "# Convert to 4-dimensional tensor.\n",
        "\n",
        "inputs = input_tensor.unsqueeze(0)"
      ],
      "metadata": {
        "id": "x1Utfg0y9J4G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week 10 Lab 1-2"
      ],
      "metadata": {
        "id": "l_X1kLluCV-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model, using weights\n",
        "that have been trained using the ImageNet dataset. Just as we did in\n",
        "previous examples, we standardize the input images because the ResNet50 model expects them to be standardized, using parameters derived from the training dataset that\n",
        "was used to train the model.Convert to probabilities, since final SoftMax activation is not in pretrained model and then print the predictions after first calling\n",
        "the convenience method sort(), which retrieves the labels\n",
        "in textual form.\n"
      ],
      "metadata": {
        "id": "TB2ebmPiA9mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model.\n",
        "\n",
        "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "model.eval()\n",
        "\n",
        "# Transfer model to GPU.\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Do prediction.\n",
        "\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  outputs = model(inputs)\n",
        "\n",
        "# Convert to probabilities, since final SoftMax activation is not in pretrained model. \n",
        "probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "\n",
        "# Print class ID for top 5 predictions.\n",
        "\n",
        "_, indices = torch. sort(probabilities, descending=True)\n",
        "\n",
        "for i in range(0, 5):\n",
        "\n",
        "  print('ImageNet class:', indices[i].item(),', probability = %4.3f' % probabilities[indices[i]].item())\n",
        "\n",
        "# Show image.\n",
        "\n",
        "image.show()"
      ],
      "metadata": {
        "id": "slFmq0Zi9CAg",
        "outputId": "9df50416-d56e-4a85-9117-e82058c74291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageNet class: 207 , probability = 0.650\n",
            "ImageNet class: 208 , probability = 0.332\n",
            "ImageNet class: 216 , probability = 0.003\n",
            "ImageNet class: 222 , probability = 0.003\n",
            "ImageNet class: 257 , probability = 0.002\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}